{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåæ CSIRO Image2Biomass: Custom Exploratory Data Analysis (EDA)\n",
    "\n",
    "This notebook provides a customizable framework for exploring the CSIRO Image2Biomass competition data. It incorporates our newly engineered weather features and aims to provide insights into data quality, statistical patterns, and relationships between features and target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "\n",
    "# --- Configuration --- \n",
    "DATA_PATH = Path('C:/Users/Ayush/OneDrive/Desktop/kaggle/New folder')\n",
    "IMAGE_TRAIN_PATH = DATA_PATH / 'train'\n",
    "IMAGE_TEST_PATH = DATA_PATH / 'test'\n",
    "\n",
    "# --- Load Data ---\n",
    "def load_all_data(data_path):\n",
    "    print(\"Loading data...\")\n",
    "    train_df = pd.read_csv(data_path / 'train.csv')\n",
    "    test_df = pd.read_csv(data_path / 'test.csv')\n",
    "    train_weather_features = pd.read_csv(data_path / 'train_weather_features.csv')\n",
    "\n",
    "    # Pivot training data to have one row per image\n",
    "    train_pivot = train_df.pivot_table(\n",
    "        index=['image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm'], \n",
    "        columns='target_name', \n",
    "        values='target'\n",
    "    ).reset_index()\n",
    "\n",
    "    # Merge weather features\n",
    "    train_pivot = pd.merge(train_pivot, train_weather_features, on='image_path', how='left').fillna(0)\n",
    "\n",
    "    # Feature Engineering for dates\n",
    "    train_pivot['Sampling_Date'] = pd.to_datetime(train_pivot['Sampling_Date'])\n",
    "    train_pivot['month'] = train_pivot['Sampling_Date'].dt.month\n",
    "    train_pivot['year'] = train_pivot['Sampling_Date'].dt.year\n",
    "    train_pivot['day_of_year'] = train_pivot['Sampling_Date'].dt.dayofyear\n",
    "    train_pivot.drop('Sampling_Date', axis=1, inplace=True)\n",
    "\n",
    "    print(\"Data loaded and preprocessed.\")\n",
    "    return train_pivot, test_df\n",
    "\n",
    "train_pivot_df, test_df = load_all_data(DATA_PATH)\n",
    "print(f\"Train data shape: {train_pivot_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "train_pivot_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 1. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_missing_values(df, title=\"Missing Values Heatmap\"):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def display_missing_values_table(df):\n",
    "    missing_data = df.isnull().sum()\n",
    "    missing_data = missing_data[missing_data > 0]\n",
    "    missing_percent = (df.isnull().sum() / len(df) * 100)\n",
    "    missing_percent = missing_percent[missing_percent > 0]\n",
    "    \n",
    "    missing_info = pd.DataFrame({\n",
    "        'Missing Count': missing_data,\n",
    "        'Missing Percent': missing_percent\n",
    "    }).sort_values(by='Missing Percent', ascending=False)\n",
    "    \n",
    "    if missing_info.empty:\n",
    "        print(\"No missing values found.\")\n",
    "    else:\n",
    "        print(\"Missing Values Information:\")\n",
    "        print(missing_info)\n",
    "\n",
    "display_missing_values_table(train_pivot_df)\n",
    "plot_missing_values(train_pivot_df, \"Training Data Missing Values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà 2. Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_target_distributions(df, targets):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, target in enumerate(targets):\n",
    "        plt.subplot(2, 3, i + 1)\n",
    "        sns.histplot(df[target], kde=True)\n",
    "        plt.title(f'Distribution of {target}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_correlation_heatmap(df, features, targets):\n",
    "    cols_to_correlate = features + targets\n",
    "    corr_matrix = df[cols_to_correlate].corr()\n",
    "    plt.figure(figsize=(14, 12))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "    plt.title('Correlation Heatmap of Features and Targets')\n",
    "    plt.show()\n",
    "\n",
    "target_cols = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n",
    "numerical_features = ['Pre_GSHH_NDVI', 'Height_Ave_cm', 'total_rainfall_last_30d', \n",
    "                      'avg_min_temp_last_30d', 'avg_max_temp_last_30d', 'avg_sunshine_last_30d', \n",
    "                      'days_with_rain_last_30d']\n",
    "\n",
    "plot_target_distributions(train_pivot_df, target_cols)\n",
    "plot_correlation_heatmap(train_pivot_df, numerical_features, target_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üó∫Ô∏è 3. Metadata Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical_distribution(df, column, title=None):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(data=df, x=column, order=df[column].value_counts().index)\n",
    "    plt.title(title or f'Distribution of {column}')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_vs_target(df, feature, target, kind='scatter', title=None):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if kind == 'scatter':\n",
    "        sns.scatterplot(data=df, x=feature, y=target)\n",
    "    elif kind == 'box':\n",
    "        sns.boxplot(data=df, x=feature, y=target)\n",
    "    plt.title(title or f'{feature} vs {target}')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.show()\n",
    "\n",
    "categorical_features = ['State', 'Species', 'month', 'year']\n",
    "for col in categorical_features:\n",
    "    plot_categorical_distribution(train_pivot_df, col)\n",
    "\n",
    "plot_feature_vs_target(train_pivot_df, 'Pre_GSHH_NDVI', 'Dry_Total_g')\n",
    "plot_feature_vs_target(train_pivot_df, 'Height_Ave_cm', 'Dry_Total_g')\n",
    "plot_feature_vs_target(train_pivot_df, 'avg_min_temp_last_30d', 'Dry_Total_g', kind='scatter')\n",
    "plot_feature_vs_target(train_pivot_df, 'total_rainfall_last_30d', 'Dry_Total_g', kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üñºÔ∏è 4. Image Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_with_metadata(df, image_dir, n_images=5, sort_by=None, ascending=True, filters=None):\n",
    "    display_df = df.copy()\n",
    "    \n",
    "    if filters:\n",
    "        for col, value in filters.items():\n",
    "            display_df = display_df[display_df[col] == value]\n",
    "            \n",
    "    if sort_by:\n",
    "        display_df = display_df.sort_values(by=sort_by, ascending=ascending)\n",
    "        \n",
    "    display_df = display_df.head(n_images)\n",
    "    \n",
    "    if display_df.empty:\n",
    "        print(\"No images found matching the criteria.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(20, 5 * n_images))\n",
    "    for i, (idx, row) in enumerate(display_df.iterrows()):\n",
    "        img_path = image_dir / row['image_path']\n",
    "        if not img_path.exists():\n",
    "            img_path = image_dir / Path(row['image_path']).name # Try without subfolder if path is 'train/ID.jpg'\n",
    "            if not img_path.exists():\n",
    "                print(f\"Image not found: {image_dir / row['image_path']}\")\n",
    "                continue\n",
    "        \n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        plt.subplot(n_images, 1, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        title_str = f\"ID: {Path(row['image_path']).stem} | State: {row['State']} | Species: {row['Species']} | \" \
",
    "                    f\"NDVI: {row['Pre_GSHH_NDVI']:.2f} | Height: {row['Height_Ave_cm']:.2f} | \" \
",
    "                    f\"Total Dry: {row['Dry_Total_g']:.2f}g | Rainfall (30d): {row['total_rainfall_last_30d']:.1f}mm\"\n",
    "        plt.title(title_str, fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example Usage:\n",
    "print(\"\\n--- Images with Highest Total Dry Biomass ---\")\n",
    "display_images_with_metadata(train_pivot_df, IMAGE_TRAIN_PATH, n_images=3, sort_by='Dry_Total_g', ascending=False)\n",
    "\n",
    "print(\"\\n--- Images with Lowest Total Dry Biomass ---\")\n",
    "display_images_with_metadata(train_pivot_df, IMAGE_TRAIN_PATH, n_images=3, sort_by='Dry_Total_g', ascending=True)\n",
    "\n",
    "print(\"\\n--- Images from NSW with High NDVI ---\")\n",
    "display_images_with_metadata(train_pivot_df, IMAGE_TRAIN_PATH, n_images=3, sort_by='Pre_GSHH_NDVI', ascending=False, filters={'State': 'NSW'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç 5. Insights for Modeling\n",
    "\n",
    "*(This section would typically contain textual interpretations of the EDA findings, highlighting potential feature interactions, data imbalances, and strategies for model development. Since this is a template, specific insights would be derived after running the cells above.)*\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
